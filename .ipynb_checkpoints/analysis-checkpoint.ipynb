{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "### This code analyzes tables with the following removed:\n",
    "* **Multi** terrain type\n",
    "* Any row that has null entries which was a consequence of scraping thousands of webpages with sometimes different table structures; this killed about 27% of the scraped data\n",
    "* Chip time and gun time have been combined to form a minimum time in mins\n",
    "* Deleted **ALL** races without the corresponding GPX file therefore this is the cross-referenced output\n",
    "* Some GPX information has been added to tables, e.g. elevation and sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important maps\n",
    "conversion_map = {'1M':1.0, '3K':1.86, '2M':2.0, '5K':3.1, '4M':4.0,\n",
    "                 '5M':5.0, '6M':6.0, '10K':6.2, 'QM':6.55, '7M':7.0,\n",
    "                 '10M':10.0, 'HM':13.1, 'Mar':26.2}\n",
    "race_order= ['1M', '3K', '2M', '5K', '4M','5M', '6M', '10K',\n",
    "             'QM', '7M', '10M', 'HM', 'Mar']\n",
    "age_order = ['U15','U17','U20','U23','SEN','V35','V40','V45',\n",
    "             'V50','V55','V60','V65','V70','V75','V80','V85']\n",
    "#age_map = {'U11':0,'U13':0,'U15':0,'U17':0,'U20':0,'U23':0,\n",
    "#           'SEN':1,'V35':2,'V40':2,'V45':3,'V50':3,'V55':4,\n",
    "#           'V60':4,'V65':5,'V70':5,'V75':5,'V80':5,'V85':5}\n",
    "age_map = {'U11':0,'U13':1,'U15':2,'U17':3,'U20':4,'U23':5,\n",
    "                  'SEN':6,'V35':7,'V40':8,'V45':9,'V50':10,'V55':11,\n",
    "                  'V60':12,'V65':13,'V70':14,'V75':15,'V80':16,'V85':17}\n",
    "dist_map = {'1M':1, '3K':2, '2M':3, '5K':4, '4M':5,\n",
    "            '5M':6, '6M':7, '10K':8, 'QM':9, '7M':10,\n",
    "            '10M':11, 'HM':12, 'Mar':13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60% faster than walking is expected to take 362.2 minutes\n",
      "TIME CUT = 362.212\n"
     ]
    }
   ],
   "source": [
    "speed = 3.1*1.6 #mph\n",
    "if race_type == 'Mar':\n",
    "    speed = 3.1*1.4\n",
    "dist = conversion_map[race_type]\n",
    "walk_time = (dist / speed)* 60\n",
    "print('60%% faster than walking is expected to take %1.1f minutes' % walk_time)\n",
    "print('TIME CUT = %1.3f' % walk_time)\n",
    "TIME_CUT = walk_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows, cols = 104941, 13\n"
     ]
    }
   ],
   "source": [
    "datadir = '/home/freddy/insight/data/'\n",
    "filename = datadir + 'data_overlaps_with_gpx_cleaned.csv'\n",
    "df = pd.read_csv(filename)\n",
    "print('rows, cols = {0}, {1}'.format(df.shape[0], df.shape[1]))\n",
    "df=df.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.age_group != 'V115']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race_title\n",
       "10K    15650\n",
       "10M     2113\n",
       "1M       199\n",
       "2M        59\n",
       "3K       421\n",
       "4M       216\n",
       "5K      2623\n",
       "5M      4791\n",
       "6M       272\n",
       "7M       411\n",
       "HM      3802\n",
       "Mar    73948\n",
       "QM       434\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.groupby(['race_title'],as_index=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_old.groupby(['age_group'],as_index=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df.race_title==race_type]\n",
    "subdf=df[df.race_title==race_type].groupby(['meeting_id','sex','age_group','race_title'],as_index=False)['min_time'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if race_type == '10K':\n",
    "    f, ax = plt.subplots(1,1, figsize=(12,4))\n",
    "    A=df.groupby(['event_title','min_time'], as_index=False).count()\n",
    "    Ar = A[A.event_title=='RunThrough Olympic Park 10K']\n",
    "    Al = A[A.event_title=='RunThrough Chase The Moon Olympic Park 10K']\n",
    "    plt.hist(list(Al.min_time.values), 50, \n",
    "             alpha=0.5, label='Day', facecolor='g')\n",
    "    plt.hist(list(Ar.min_time.values), 50, \n",
    "             alpha=0.5, label='Night',facecolor='b')\n",
    "    plt.legend(loc='upper right',frameon=False, prop={'size':20})\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Median Finish Time (min)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = df.groupby(['meeting_id','race_location','event_title'],as_index=False).count()\n",
    "events = set(list(location_df['event_title'].values))\n",
    "\n",
    "event_map = {}\n",
    "for i in events:\n",
    "    subdf = location_df.loc[location_df['event_title']==i]\n",
    "    subdf_map = {}\n",
    "    for index, row in subdf.iterrows():\n",
    "        ID  = row.meeting_id\n",
    "        loc = row.race_location\n",
    "        subdf_map[ID] = loc\n",
    "    event_map[i] = subdf_map\n",
    "temp = dict(zip(location_df.meeting_id,location_df.event_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_avgtime = df.groupby(['meeting_id'], as_index=False)['min_time'].median()\n",
    "times = dict(zip(id_avgtime.meeting_id, id_avgtime.min_time))\n",
    "time_bar = 0.0\n",
    "for i in list(times.values()):\n",
    "    time_bar += i\n",
    "time_bar /= float(len(list(times.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast=(df.sort_values('min_time').groupby(['meeting_id'],as_index=False).first())['min_time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(fast, 20,\n",
    "                            facecolor='g', alpha=0.75)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Fastest Run Times for %s' % race_type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(times.values(), 20,\n",
    "                            facecolor='g', alpha=0.75)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Median Time For %s Races (min)' % race_type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt(row):\n",
    "    time = row.min_time\n",
    "    med_time = times[row.meeting_id]\n",
    "    return float(time-med_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dt'] = df.apply(get_dt,axis=1)\n",
    "print(df.shape)\n",
    "df = df.drop(df[df.min_time > TIME_CUT].index)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for index,row in df.iterrows():\n",
    "    sex  = row.sex\n",
    "    age  = row.age_group\n",
    "    time = row.min_time \n",
    "    ID   = row.meeting_id\n",
    "    # Need a smarter method for this...I tried building a dictionary like I would\n",
    "    # normally do in C++ but it doesn't work that way in python to my knowledge\n",
    "    #temp_row = subdf.loc[(subdf['age_group']==age) & \n",
    "    #                     (subdf['sex']==sex) &\n",
    "    #                     (subdf['meeting_id'] == ID)]\n",
    "    #avg_time = (temp_row.min_time).item()\n",
    "    avg_time = times[ID]\n",
    "    Y.append(0 if (time<=avg_time) else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dt = list(df['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "n, bins, patches = plt.hist(Y_dt, 100, density=True, \n",
    "                            facecolor='g', alpha=0.75)\n",
    "#plt.axis([10, 35, 0.0, 0.175])\n",
    "plt.grid(True)\n",
    "plt.xlabel('t - <t> (min)')\n",
    "(mu,sig) = norm.fit(Y_dt)\n",
    "y = mlab.normpdf(bins, mu, sig)\n",
    "l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "\n",
    "plt.show()\n",
    "print('Mu,sigma = %1.3f, %1.3f' % (mu,sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = conversion_map[race_type]\n",
    "X['sum_up'] = X['sum_up']/norm\n",
    "X['sigma']  = X['sigma']/norm\n",
    "print('Normalization = %1.4f miles' % norm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpx = X.groupby(['meeting_id'],as_index=False).mean()\n",
    "gpx = gpx.drop(['position', 'race_dist', 'min_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['position','meeting_id', 'race_title', 'race_dist',\n",
    "            'event_title','race_location', 'dt'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xrow in [X]:\n",
    "    xrow['sex'] = xrow['sex'].map( {'W': 1, 'M': 2} ).astype(int)\n",
    "    xrow['age_group'] = xrow['age_group'].map( age_map )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = \\\n",
    "    train_test_split(X, Y_dt, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std  = stdsc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "This was attempt number 1 and too simple as the output has been forced to be binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X, Y)\n",
    "beta = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(clf.coef_))], axis = 1)\n",
    "print('Logistic Regression Results:')\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression().fit(X, Y_dt)\n",
    "lr = reg.coef_\n",
    "beta_dict = {'age_group': lr[0], 'sex':lr[1], \n",
    "             'min_time':lr[2], 'sum_up':lr[3], 'sigma':lr[4],\n",
    "            'diff':lr[5]}\n",
    "beta = pd.DataFrame(list(beta_dict.items()))\n",
    "print('Linear Regression Results:')\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_v2 = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "y_pred = reg_v2.predict(X_test)\n",
    "score = reg_v2.score(X_test,y_test)\n",
    "print('Score = {0}'.format(score))\n",
    "print(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "ridge = linear_model.Ridge(alpha=0.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "ridge.fit(X_train, y_train)\n",
    "    # calculate errors\n",
    "new_train_error = mean_squared_error(y_train, ridge.predict(X_train))\n",
    "new_test_error = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "print(new_train_error, new_test_error)\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for index, row in X.iterrows():\n",
    "    rowidx=0\n",
    "    sum = 0.0\n",
    "    for i in row:\n",
    "        sum += i*beta.values[rowidx][1]\n",
    "        rowidx+=1\n",
    "    d.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "n, bins, patches = plt.hist(d, 200, density=True, \n",
    "                            facecolor='black', alpha=0.75)\n",
    "#plt.axis([20, 120, 0.1, 200])\n",
    "plt.grid(True)\n",
    "plt.xlabel('Score Distribution for Marathon Courses')\n",
    "(mu,sig) = norm.fit(d)\n",
    "y = mlab.normpdf(bins, mu, sig)\n",
    "#l = plt.plot(bins, y, 'r--', linewidth=4)\n",
    "#plt.yscale('log')\n",
    "print('Mu,sigma = %1.3f, %1.3f' % (mu,sig))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(lo, hi, n, bins):\n",
    "    integral = 0.0\n",
    "    for idx in range(lo,hi):\n",
    "        integral += n[idx] * (bins[idx+1]-bins[idx])\n",
    "    return integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals, yvals, dx = [],[],[]\n",
    "for idx in range(0,len(n)):\n",
    "    integral = integrate(0, idx, n, bins)\n",
    "    binpos =  0.5*(bins[idx+1] + bins[idx])\n",
    "    dx.append(bins[idx+1] - bins[idx])\n",
    "    success = False\n",
    "    if integral > 0.995:\n",
    "        success = True\n",
    "        integral = 1.0\n",
    "    xvals.append(binpos)\n",
    "    yvals.append(integral)\n",
    "    if success:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(xvals,yvals,color='black')\n",
    "plt.xlabel('Score Distribution for Marathons')\n",
    "plt.ylabel('Difficulty Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_output = 'inputs/{0}/'.format(race_type)\n",
    "#dump_output = 'inputs/testing/10K/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out age and sex map\n",
    "f1 = open('{0}age_map_{1}.csv'.format(dump_output,race_type), 'w')\n",
    "for key, val in age_map.items():\n",
    "    f1.write('%s,%d\\n'%(key,val))\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the betas\n",
    "beta.to_csv('{0}beta_{1}.csv'.format(dump_output,race_type),sep=',', \n",
    "            index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the integral plot\n",
    "f = open('{0}d_dist_{1}.csv'.format(dump_output,race_type), 'w')\n",
    "f.write('bin,xval,yval,dx\\n')\n",
    "for idx in range(0,len(xvals)):\n",
    "    f.write('%d,%1.5f,%1.5f,%1.5f\\n' % (idx,xvals[idx],yvals[idx], dx[idx]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_avgtime.to_csv('{0}avg_times_{1}.csv'.format(dump_output,race_type),sep=',',\n",
    "            index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the GPX information used\n",
    "gpx.to_csv('{0}gpx_info_{1}.csv'.format(dump_output,race_type),sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the event list\n",
    "f2 = open('{0}event_title_list_{1}.csv'.format(dump_output,race_type), 'w')\n",
    "f2.write('event\\n')\n",
    "for key, val in event_map.items():\n",
    "    f2.write('%s\\n'%key)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open('{0}event_title_list_v2_{1}.csv'.format(dump_output,race_type), 'w')\n",
    "f3.write('ID,event\\n')\n",
    "for key, val in temp.items():\n",
    "    f3.write('%d,%s\\n'%(key,val))\n",
    "f3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LETS MERGE ANYTHING USEFUL FOR LATER CALCULATIONS\n",
    "frame2sql_temp = id_avgtime\n",
    "frame2sql = pd.merge(frame2sql_temp,gpx,on='meeting_id')\n",
    "evt_temp = pd.DataFrame.from_dict(temp,orient='index')\n",
    "output = frame2sql.merge(evt_temp,left_on='meeting_id',right_index=True)\n",
    "output['race_type'] = race_type\n",
    "output.to_csv('{0}OUTPUT_{1}.csv'.format(dump_output,race_type),sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
